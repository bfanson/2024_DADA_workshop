[
  {
    "path": "sessions/day1-getting-data-into-shape/",
    "title": "Day 1: Getting data into shape",
    "description": "Tidyverse world",
    "author": [
      {
        "name": "Ben Fanson",
        "url": "https://bfanson.github.io/2024DADAworkshop/"
      }
    ],
    "date": "2024-09-04",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nDay’s objectives\r\nKey packages\r\nWorkshop project: Wetland Data\r\nWorkflows\r\nExamples of workflows\r\nmine\r\nPaul’s\r\nCommonalities\r\n\r\nAdvantages of workflow\r\n“Laziness” in data analysis programming\r\n\r\n\r\nRstudio\r\nBasics\r\nTips and tricks\r\n\r\nSetting up Rproject\r\nRproject\r\nProject directory/folder structure\r\n\r\nVersion Control: Git/Github [Advanced]\r\nProgramming good technique\r\nHelp!!!!!!!!\r\nUsing AI for coding\r\n\r\nTidyverse framework\r\nHistorical context\r\nBasic principles\r\nTibbles\r\nPipes: %>% (magittr package)\r\nBuilding “sentences”\r\n“Odd” looking uses\r\nold vs. new: %>% vs. |>\r\n\r\n\r\nImporting\r\nSaving the data files\r\nExcel files\r\nCSV/Table\r\nDatabase (Advanced)\r\ncolumn names\r\nempty rows\r\nAdvanced topic(s)\r\nImporting lots of files with same (or similar-ish) structure\r\nExcel files and importing color metadata\r\n\r\nHands-on\r\n\r\nData cleaning\r\nchecking your data - each column\r\nknow the design so you can check for issues\r\nnotes on missing values\r\nNA and NaN in R\r\nother similar values: NaN, Inf\r\nuseful functions\r\nNAs in other functions\r\n\r\n\r\n\r\nJoins\r\nProject step\r\ntypes of joins\r\nTips and tricks\r\n\r\nRestructuring\r\nString manipulation\r\nDate/time\r\nKey date concepts\r\ndate using lubridate\r\nlubridate vs. base\r\n\r\nKey datetime concepts\r\n\r\nSaving the clean data\r\nRevisiting day’s objectives\r\nAdvanced topics\r\nQuality check packages\r\nvalidate package\r\npointblank package\r\nBig Data\r\n\r\nHands-on component\r\nResources\r\n\r\nDay’s objectives\r\nUnderstand workflow, why it is important, and how to do it using Rstudio/R\r\nHave an understanding of the tidyverse framework and its key packages\r\nProvide a bit of context/framework to working in R as many of us have learned piecemeal\r\nWork through an example\r\nKey packages\r\n\r\nWorkshop project: Wetland Data\r\n\r\n\r\n Download project data\r\n\r\n\r\nWorkflows\r\nExamples of workflows\r\nmine\r\nPaul’s\r\nCommonalities\r\nAdvantages of workflow\r\n“Laziness” in data analysis programming\r\nA crucial attribute of workflow is “laziness”. As several of you will know, I will often say that I am “lazy” in my programming. I do not want to think about coding anymore than have to. I have a set workflow that I basically always follow as I showed above as well as set programming style. I want to spend my time thinking about science (and statistical models), not programming.\r\nThere are two distinct advantages to this:\r\nreduce cognitive load\r\nwe have limited working memory. A workflow minimizes wasted time on the logistics of the analysis (how to set up folder, naming of files, naming of variables, how the analysis will be structured).\r\n\r\ndistraction from the analysis by coding\r\ndistraction theory - average focus time is 4 min\r\nif I have a set routine, I can go into automatic mode and can efficiently\r\nmore you have to break away from this routine (deep focus), higher the chance of going down rabbitholes (or check that email)\r\n\r\nRstudio\r\nYou can find a variety of cheatsheets at https://posit.co/resources/cheatsheets/\r\n\r\nSee Rstudio IDE to Positron https://github.com/posit-dev/positron/wiki for note about new IDE\r\nBasics\r\nassume familiar with\r\nmight want to turn off .Rdata so everything is fresh on startup (no issues with previous objects so completely reproducible)\r\n\r\nTips and tricks\r\ntab\r\nfills in paths\r\nhexcode color coating\r\ncode folding (#)\r\ninsert pipe: ctrl+shift+M %>%\r\ncomment: ctrl + shift + C\r\nfind in all files\r\nclick on object in “Data” to view and filter the dataset\r\nSetting up Rproject\r\nRproject\r\nProject directory/folder structure\r\nVersion Control: Git/Github [Advanced]\r\nAs part of my due-diligence, I have to mention version control. In short, version control is external software that keeps track of all your changes (so you can go back if something breaks in your code) and very helpful with collaborations (e.g. allowing you both code away and then merging those changes).\r\nFor R/Rstudio, Git/Github is the most popular. Now, Git is the version control software locally on your computer and it does the tracking of all changes In contrast, Github is an online platform in which you can upload those changes (and project folder/files) and is mainly useful for the collaboration/sharing (plus some other useful features)\r\nKey points on Git/Github:\r\nIf not collaborating, the overhead of Git (learning, initial setup, random breaks) might not worth it to you. You still have version histories via Onedrive to save you (not as easy to shift through as Git).\r\nIf collaborating, it really is the best approach that will save you effort in the long run.\r\nIt is worth playing around with Github online so you know how to navigate the website (this workshop will help with that). Github is a rich resource with example code and useful packages not on CRAN. Github project (aka repositories) can look intimidating at first.\r\nRstudio has git integration that makes it easier to work with, though the github desktop\r\nGithub has Github pages which is hosting this website [workflow: 1) write RMD files in Rstudio; 2) upload to Github; 3) Github publishes at https:username.github.io/project_id]\r\nGIT resources to get started\r\nCheatsheet: https://rstudio.github.io/cheatsheets/git-github.pdf\r\nUseful book with R focus: https://happygitwithr.com/\r\nProgramming good technique\r\nconsistent style\r\nmodularize your code (functions - slightly more advanced)\r\nHelp!!!!!!!!\r\nWhen learning and using R, you will get stuck and need help. There are variety of help sources we use on a daily basis.\r\nBuilt-in to Rstudio are help files. This provides an initial starting place if you are interested in how to use a specific function. You just need to put “?” before the function and press run: ?mean() or use the Help tab\r\nGoogle search (e.g. stackoverflow, blogs) can be really helpful for finding new functions, packages, etc.\r\nBiometrics - happy to provide guidance/tips/thoughts\r\nARI’s QEARI - hacky hour or Teams chat\r\nAI is becoming more and more useful [I am finding the most useful]\r\nUsing AI for coding\r\nA few AI I use regularly:\r\nCopilot (Microsoft): allrounder AI which we have a free subscription at ARI. It does a decent job [I use this one daily]\r\nChatGPT: another allrounder similar to Copilot\r\nClaude: prefer this one for writing text but seems to work well too\r\nFor this workshop, I will stick to Copilot given the accessibility for everyone.\r\nFor those not regularly using AI, there are a few things that can help when running your searches for help:\r\nwhen asking for an example, include lots of specific to get closer to what you want. You may want to tell it to use only tidyverse functions for the example code. I often ask it to use a built-in dataset for the example so that I can check it right away.\r\nExperiment and Iterate: Don’t be afraid to experiment with the code generated by AI. Modify it, run it, and see what happens. If something is not working, you can ask point out the error and see if it can fix it\r\nUse AI for Debugging: If you encounter errors, AI tools can help you debug your code. They can suggest fixes and optimizations, making the debugging process less daunting.\r\nTidyverse framework\r\n\r\nHistorical context\r\nbase R [the packages included when you install R the first time]\r\nbase, stats, grid, utils, …\r\n\r\n\r\n# example of getting a plot using base\r\n  ds <- mtcars  # grab the built-in mtcars dataset\r\n  ds <- ds[, c('mpg','hp')]   # select just the columns you want\r\n  ds$l_100km <- 1/( ds$mpg/3.78 * 1.6 )*100 # convert mile per gallon to liters / 100km\r\n  plot( ds$l_100km ~ ds$hp )  # plot relationship between horsepower and km/l\r\n\r\n\r\nquirky things about R: factors vs character, NAs,\r\nlubridate fixed date quirks\r\nlack of consistency within base and between packages\r\ndata argument might be first or last\r\nBasic principles\r\nhuman-centered\r\nreadable to humans\r\nuses verbs like mutate, select, filter, summarise\r\nuses sentence like structure: noun -> verb -> verb [ Paul -> walks (to work) -> sets up ( his computer) -> creates a plot -> saves plot (to a file) -> calls it day -> walks (home) ]\r\n\r\nconsistent\r\nwhen using tidy functions, you get consistent output data structure (called a tibble)\r\n\r\n\r\n\r\n  # an example of tidyverse consistent structure\r\n  class(mtcars)   # data.frame\r\n  head(mtcars)    # notice the rowlabels\r\n  View(mtcars)    # see the rownames in the spreadsheet\r\n  as_tibble(mtcars,rownames = 'make')  # tidyverse datasets (tibbles) never have rownames\r\n\r\n\r\n\r\ncomposable (chunks)\r\nTibbles\r\nI mentioned briefly above about “tibbles”\r\ntibble is data.frame v2.0\r\nbetter printing of the data\r\nhandles some of the quirky things that caught up people\r\ncolumn names\r\n\r\nPipes: %>% (magittr package)\r\nA key component of tidyverse world is the concept of “pipes”. The pipe connects multiples steps into a single sequence of commands.\r\n\r\nJust to make things harder, a new pipe |> has been introduced. It is very similar to %>% but it does act a little different. We will just teach %>% because we are set in our ways\r\nBuilding “sentences”\r\n\r\n\r\n  library(tidyverse)\r\n  head(mtcars)\r\n  mtcars %>% head(10)  # get mtcars, pass to head function, take the first 10 rows\r\n  \r\n# sentence using tidy functions we will dive into below...just follow basic logic\r\n  mtcars %>% \r\n    slice_head(n=10) %>%  # take first 10 rows   \r\n    mutate( mpl = round( mpg/3.79,2 ) ) %>%  # convert mpg to miles per liter (mpl)\r\n    select( mpg, mpl )  # keep just the mpg and mpl columns \r\n\r\n# placeholder \".\"\r\n  mtcars %>% head(5)    \r\n  mtcars %>% head(.,5)  # same as above but explicitly using . to denote the input\r\n\r\n  # example where you want to input the dataset not into first argument spot\r\n  mtcars %>% lm(mpg~hp) %>% summary()  # fails as it is trying lm(formula=mtcars, data=mpg~hp )\r\n  mtcars %>% lm(mpg~hp, data=.) %>% summary()  # referencing the input by \".\"\r\n\r\n\r\n“Odd” looking uses\r\nWith %>% it is worth being aware that you will see different variations that look odd. I show a few examples below.\r\n\r\nNote that you can have different variations using %>% that might look odd. E.g. data %>% head or data %>% .$var. Just be beware\r\n\r\n\r\n  mtcars %>% head  # lack of brackets\r\n  mtcars %>% head(n=3) %>%  bind_rows( ., .)   # multiple \".\" example\r\n  mtcars %>% .$mpg   # grabs a specific column - combining tidyverse with base approaches \r\n  mtcars %>% {c( mean=mean(.$mpg), median=median(.$mpg) ) }  # curly bracket example using \".\" and $ - prevents putting . into c(., mean(.$mpg), median(.$mpg))\r\n\r\n\r\nold vs. new: %>% vs. |>\r\n|> is considered to be “simple” now compared to %>%\r\nare some differences mainly associated with referring to the passed\r\nTip - set a shortcut for… Ctrl-Shift-M\r\n\r\n  library(tidyverse)\r\n  head(mtcars)\r\n  mtcars %>% head()\r\n  mtcars |> head() # newer version \r\n\r\n# examples of differences (advanced)\r\n  mtcars %>% head # works\r\n  mtcars |> head  # fails  (must have brackets)\r\n  mtcars |> head()  # works  (must have brackets)\r\n\r\n  #subselecting\r\n  mtcars %>% .$mpg\r\n  mtcars |>  .$mpg  # $ not supported\r\n  mtcars |>  pull(mpg)  # use pull\r\n\r\n  mtcars %>% head(x=., 10) # . works for %>% \r\n  mtcars |>  head(x=., 10)  # . placeholder does not work\r\n  mtcars |>  head(x=_, 10)  # _ placeholder instead\r\n  mtcars |>  head(n=10, x=_)  # _ placeholder instead\r\n  mtcars  %>%   head(n=10, .)  # can place without argument specified\r\n  mtcars  %>%   head(n=10, _)  # must you argument if not in first position\r\n\r\nImporting\r\nSaving the data files\r\nExcel files\r\n\r\nKey functions\r\n\r\n\r\n  readxl::read_xls()\r\n  readxl::read_xlsx()\r\n\r\n\r\nTips and tricks\r\nNAs - defining\r\nrename columns\r\nreading in more rows to get column type correct\r\nsetup excel file to have NA\r\n\r\n\r\n  readxl::read_xls()\r\n  readxl::read_xlsx()\r\n\r\n\r\nCSV/Table\r\n\r\n\r\n\r\n#\r\n  readr::read_csv()\r\n  readr::read_table()\r\n\r\n# brings in as tibble  \r\n  ds_base <- read.csv('data/raw/mtcars.csv')  \r\n    head(ds_base)\r\n    class(ds_base)\r\n\r\n  ds_tidy <- read_csv('data/raw/mtcars.csv')  \r\n    head(ds_tidy)\r\n    class(ds_tidy)\r\n\r\n\r\nDatabase (Advanced)\r\nSome possible packages to check:\r\nRMySQL: This package allows you to connect to MySQL databases and execute SQL queries1.\r\nRPostgreSQL: This package is designed for connecting to PostgreSQL databases1.\r\nRSQLite: This package is used for SQLite databases and is great for lightweight, serverless database applications1.\r\nRODBC: This package provides a way to connect to any database that supports ODBC (Open Database Connectivity)1.\r\nRJDBC: This package uses Java Database Connectivity (JDBC) to connect to a wide variety of databases1.\r\ncolumn names\r\nwhat makes a good column name\r\nno whitespaces, no special characters, not too long, (for me) all lowercase\r\nprefixes or suffixes (useful for select functions)\r\n\r\n\r\n  warning('create example excel file in')\r\n  ds <- tibble::tibble(`First column`=1:5, `% column`= runif(5) )\r\n  janitor::clean_names( ds )\r\n\r\n\r\nempty rows\r\n\r\n\r\n  ds <- tibble::tibble(`First column`=c(1:5,NA), `% column`= c(runif(5),NA ), final=c() )\r\n  janitor::remove_empty( ds )\r\n\r\n  janitor::remove_empty( ds ) %>% \r\n      janitor::clean_names(  )\r\n\r\n\r\nAdvanced topic(s)\r\nImporting lots of files with same (or similar-ish) structure\r\nThere are times that you will want to import 10s or 100s of files that are structurally the same (e.g. camera data, acoustic tagging data). I use the purrr package on almost daily basis. This package was created to help simplify the apply family of functions (e.g. apply,lapply,sapply,mapply) into a more intuitive nomenclature (like the rest of tidyverse). One website that gives a tutorial is https://jennybc.github.io/purrr-tutorial/ (but several others out there).\r\n\r\n\r\n  v_list <- dir('data/raw/tagging',full.names = T)   # get a list of files to import.  use full.names=T to relative path\r\n  importData <- function(x) read_csv( x ) %>% mutate(file_id=x) # create the function that imports a single file\r\n  ds_all <- purrr::map_df( v_list, ~importData(.x) )   # loop through each filename in v_list, combine together into new dataset\r\n\r\n\r\nNote - you could do this using for-loops but it takes more code.\r\nExcel files and importing color metadata\r\nFirst off, just don’t use cell styles (color) in excel as a way to store data. For instance, using color to indicate treatment.\r\nThat being said, you can extract that information using tidyxl package. I have had good luck with\r\nHands-on\r\nAfter setting up the folder structure for your project, you need to add your data. Here, you will download the data/ directory using link below:\r\n\r\n\r\n Download data folder for project\r\n\r\n\r\nAfter the zip file downloads, unzip and drag the data/ folder to your Rproject folder.\r\nXXXX data/raw, data/rds, data/spatial XXXX\r\n\r\nYour Task\r\nImport your data\r\nCall the Rproject projectDADA\r\nCreate subfolders: data/, R/\r\nCreate a new r script calls importData.r and save in R/ folder\r\n\r\n\r\nData cleaning\r\nany useful packages that show this information in condensed way\r\nchecking your data - each column\r\nreminder on factor vs character\r\nordering factors\r\nforcats\r\nknow the design so you can check for issues\r\nnotes on missing values\r\nreminder of different ways to handle\r\nrun model, will be dropped\r\ncauses errors (NA) in summary (na.rm=T, do not do as a default)\r\nDealing with NA\r\nNA and NaN in R\r\nunique\r\n0/0\r\nas.character( c(NaN, 1) )\r\nas.character( c(NA, 1) )\r\nn_distinct( c(NA,‘a’,‘b’) )\r\nother similar values: NaN, Inf\r\n1/0\r\nuseful functions\r\nis.na(), is.Nan(), is.Inf()\r\nNAs in other functions\r\nmean( na.rm=T)\r\nrolling()\r\nstatistical models regression example\r\noptions: delete explicitly (missing at random), imputation techniques (mean)\r\n\r\n\r\nJoins\r\n\r\n\r\n\r\n  knitr::include_graphics(\"lubridate.pdf\")\r\n\r\n\r\nknitr::include_graphics(“dplyr.pdf”)\r\n\r\nNote: joins = merges (synonyms)\r\nProject step\r\nasdf\r\ntypes of joins\r\nleft_join - the most useful join (and safest)\r\nright_join - I never use…just use left_join\r\nfull_join - I find this to be a special use\r\ninner_join - can be useful with caution\r\nTips and tricks\r\nEssential to make sure that the number of rows out matches your expectation\r\nAlmost all my joins are\r\n\r\nYour Task\r\n\r\nRestructuring\r\n\r\n\r\n\r\n  knitr::include_graphics(\"lubridate.pdf\")\r\n\r\n\r\nknitr::include_graphics(“tidyr.pdf”)\r\n\r\n\r\nYour Task\r\n\r\nString manipulation\r\n\r\n\r\n\r\n  knitr::include_graphics(\"lubridate.pdf\")\r\n\r\n\r\nknitr::include_graphics(“stringr.pdf”)\r\n\r\n\r\nYour Task\r\n\r\nDate/time\r\n\r\n\r\n\r\n  knitr::include_graphics(\"lubridate.pdf\")\r\n\r\n\r\n\r\nKey date concepts\r\ndate using lubridate\r\n\r\n\r\n# tidy way to make a date\r\n  as_date('2001-01-01') # assume Year-month-day\r\n  ymd('2001-01-01')  # better to be specific using helper function\r\n  dmy('01-01-2021') # date the other way\r\n  \r\n# dates are stored as number of days since 1970-01-01 (julian days) in R \r\n  dt <- as_date('1970-01-01')\r\n  class(dt)\r\n  as.numeric(dt)  # days since 1970-01-01 is zero\r\n  as_date('2024-01-01') %>% as.numeric() # 19,723 days since that reference date\r\n  \r\n# EXCEL WARNING: dates are stored as number of days since 1899-12-30 in Excel [leap year bug in Lotus]\r\n  ds <- readxl::read_excel('data/raw/date_example.xlsx') %>% select( starts_with('dt_') )\r\n  head(ds)  # notice the mix of numbers and text...[reminder: databases as so much better than excel]\r\n            # notice the <s3: POSIXct> column type\r\n  ( v_dt <- slice_head(ds, n=4 ) %>% pull(dt_excel) %>% as.numeric() )\r\n  as_date(v_dt)  # obviously wrong because it is using 1970-01-01 as the reference date\r\n  as_date(v_dt,origin='1899-12-30') \r\n  \r\n  # switch from POXICxt to Date\r\n  mutate(ds, dt_correct = as_date(dt_correct) ) # now it is <date>\r\n  \r\n  # for those interested, one possible fix to the column\r\n  mutate(ds, dt_fixed = case_when( !is.na(as.numeric(dt_excel)) ~ as_date( as.numeric(dt_excel), origin='1899-12-30'),\r\n                                   TRUE ~ dmy( dt_excel)  ) )\r\n  # what does AI do? Try \"using tidyverse in R, how can I fix a dataset that has a column that is text that needs to be converted to date but the column has julian days as well as date character formats in it?\"\r\n\r\n\r\n\r\n\r\n\r\n# lots of useful date helpers in lubridate  \r\n  dt <- as_date('2024-09-16')\r\n  year(dt)  # year\r\n  month(dt) # month\r\n  week(dt)  # week in the year\r\n  wday(dt)  # day in the week (monday=2)\r\n  yday(dt)  # day in the year\r\n  leap_year(dt)  # is this year a leap year?\r\n  \r\n#   \r\n  \r\n# tip using built in month vectors\r\n    month.abb[ month(dt) ] # example to get the month abbreviation\r\n    month.name[ month(dt) ] # example to get the month fullname\r\n\r\n\r\nlubridate vs. base\r\nOf course, there was a base way of making as.Date(). as_date() was created to fix a few pitfalls with as.Date(), so it is safer/better to just use as_date()\r\n\r\n\r\n# tidy vs base...  \r\n  as_date('01-11-2021')  # gives error - tidyverse\r\n  as.Date('01-11-2021')  # note the issue - base R\r\n\r\n# note assumptions still happen but tidy is a bit safer  \r\n  as_date('01-01-01') # assumes Year-month-date and that we are 20XX\r\n  as.Date('01-01-01') # no chance of correct\r\n  \r\n  dmy('01-11-2021')  # can you the helper functions to convert\r\n  as_date('01-11-2021', format='%d-%m-%Y') # or add a format for those inclined\r\n  ?strptime  # one place to find format codes\r\n  # copilot - try \"what is the date format code for 01-nov-2022 using R\"  \r\n  \r\n# timezone stuff-ups  \r\n  dt_utc <- ymd_hms(\"2024-09-01 00:50:50\")\r\n  dt_europe <- ymd_hms(\"2024-09-01 00:50:50\", tz = \"Europe/London\")\r\n  c(as_date(dt_utc), as.Date(dt_utc))\r\n  c(as_date(dt_europe), as.Date(dt_europe) )\r\n\r\n  as.Date(dt_europe, tz= tz(dt_europe) ) # have to grab the tz explicitly\r\n\r\n\r\nKey datetime concepts\r\nIt is very analagous to date concepts so let’s mirror our previous steps\r\n\r\n\r\n# tidy way to make a datetime\r\n  as_datetime('2001-01-01 10:00:00') \r\n  ymd_hms('2001-01-01 10:00:00')  # better to be specific using helper function\r\n  dmy_hm('01-Nov-2001 10:00')  # better to be specific using helper function\r\n\r\n# dates are stored as number of seconds since 1970-01-01 00:00:00 in R \r\n  dttm <- ymd_hms('1970-01-01 00:00:60')\r\n  as.numeric(dttm)  # 60 seconds\r\n\r\n# however, dates are stored as number of days since 1899-12-30 in Excel [leap year bug in Lotus]\r\n  ds <- readxl::read_excel('data/raw/date_example.xlsx') %>% select( contains('tm_'))\r\n  head(ds)  # notice the mix of numbers and text...[reminder: databases as so much better than excel]\r\n            # notice the <s3: POSIXct> column type\r\n  ( v_dt <- slice_head(ds, n=4 ) %>% pull(dt_excel) %>% as.numeric() )\r\n  as_date(v_dt)  # obviously wrong because it is using 1970-01-01 as the reference date\r\n  as_date(v_dt,origin='1899-12-30') \r\n  \r\n  # switch from POXICxt to Date\r\n  mutate(ds, dt_correct = as_date(dt_correct) ) # now it is <date>\r\n  \r\n  # for those interested, one possible fix to the column\r\n  mutate(ds, dt_fixed = case_when( !is.na(as.numeric(dt_excel)) ~ as_date( as.numeric(dt_excel), origin='1899-12-30'),\r\n                                   TRUE ~ dmy( dt_excel)  ) )\r\n  # what does AI do? Try \"using tidyverse in R, how can I fix a dataset that has a column that is text that needs to be converted to date but the column has julian days as well as date character formats in it?\"\r\n\r\n\r\nSaving the clean data\r\nAt the end of the import and clean stage, I save the dataset as an RDS file.\r\n\r\n\r\n# to save an RDS file\r\n  saveRDS( list(), \r\n          'data/rds/ards_main.rds')  # ards = Analysis-ready dataset\r\n\r\n# to read an RDS file\r\n  readRDS('data/rds/ards_main.rds')\r\n\r\n\r\nRevisiting day’s objectives\r\nUnderstand workflow, why it is important, and how to do it using Rstudio/R\r\nHave an understanding of the tidyverse framework and its key packages\r\nProvide a bit of context/framework to working in R as many of us have learned piecemeal\r\nAdvanced topics\r\nQuality check packages\r\nIf you know that you will be updating the import of files repeatedly, it can be worthwhile to do some upfront QC/QA checks to ensure that the data coming in is clean. There are some packages to help with that. There is a bit of overhead in both learning the package and implementing.\r\nvalidate package\r\nThe validate package is intended to make checking your data easy, maintainable, and reproducible. A few of the attributes:\r\ntest data against a reusable set of data validation rules\r\ninvestigate, summarise, and visualise data validation results\r\nimport and export rule sets from and to various formats\r\nfilter, select and otherwise manipulate data validation rules’\r\ninvestigate, summarise, and visualise rule sets\r\npointblank package\r\n*According to package it can methodically validate your data whether in the form of data frames or as database tables. On top of the validation toolset, the package gives you the means to provide and keep up-to-date with the information that defines your tables.*\r\n\r\nI have used before but\r\n\r\nBig Data\r\nWhen data starts to get big (millions of row), tidyverse can struggle with speed. This is huge topic but will direct you to a couple useful packages that allows you to just learn dplyr but use other quicker processes\r\ndtplyr package\r\nunder the hood it uses the data.table package\r\nbut you write code in tidy/dplyr\r\ndbplyr package if working with a database\r\nhas the database do all the processes and return the result back to R\r\ntakes advantage of cloud computing\r\n\r\nHands-on component\r\n\r\n\r\n Download Rstudio project\r\n\r\n\r\n\r\nYour Task Setup an Rproject for the workshop study\r\nBring in the second data file\r\n\r\nResources\r\nObviously, we have only scratched the surface of the topics here. Here are couple books I have used…\r\nFor a good e-book going into more details on the topics here (plus lots else)… R for Data Science\r\nFor those wishing to up their game, see Advanced R\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-09-12T00:08:47+10:00",
    "input_file": {}
  },
  {
    "path": "sessions/day2-analysis-workflow/",
    "title": "Day 2: Analysis workflow",
    "description": "Statistical analysis: 1) statistical model; 2) extracting outputs, 3) displaying(/graphing)",
    "author": [
      {
        "name": "Paul Moloney",
        "url": "https://bfanson.github.io/2024DADAworkshop/"
      }
    ],
    "date": "2024-09-03",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nHeader1\r\n\r\nHeader1\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-09-04T11:58:26+10:00",
    "input_file": {}
  },
  {
    "path": "sessions/day3-report-writing-with-quarto/",
    "title": "Day 3: Report writing with Quarto",
    "description": "Learn about report making in R",
    "author": [
      {
        "name": "Paul Moloney",
        "url": "https://bfanson.github.io/2024DADAworkshop/"
      }
    ],
    "date": "2024-09-02",
    "categories": [],
    "contents": "\r\nHeader 1\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\nHeader 2\r\nHeader 3\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-09-04T10:07:36+10:00",
    "input_file": {}
  },
  {
    "path": "sessions/day4-shiny-apps/",
    "title": "Day 4: Shiny apps",
    "description": "Building shiny apps: 1) example app; 2) basic framework; 3) deploying; 4) tips/tricks; 5) hands-on: project app.",
    "author": [
      {
        "name": "Ben Fanson",
        "url": "https://bfanson.github.io/2024DADAworkshop/"
      }
    ],
    "date": "2024-09-01",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nDay’s learning objectives\r\nKey packages\r\nProject for today\r\nPep talk\r\nLet’s build one together\r\nGo through a simple example\r\nWalk through the key bits\r\nSetting up the app\r\n\r\nStructure of the file\r\nUI (= user interface)\r\nStep 1: pick a layout\r\nStep 2: create the inputs objects: buttons, inputs, drop-down menu\r\n\r\ninput\r\nserver\r\noutput\r\nFolder structure\r\n\r\nLittle more on the server side\r\nReactivity\r\n\r\nThink about how shiny Apps might be useful\r\nVisualising data for clients\r\nData sharing - upload\r\nModel simulations\r\nCreating a shiny app using Rstudio\r\n\r\nShiny Templates\r\n\r\nDashboards\r\nshinydashboards package\r\nflexdashboard package\r\n\r\n\r\nDeploy your App\r\nARI shiny account\r\nSetting up a shiny account\r\n\r\nlinking your Rstudio to shiny server\r\nDeploying your app\r\nArchiving/deleting your app\r\nPublishing Public apps\r\nShiny Login Passwords/Security\r\nPublic/private settings\r\nLogin\r\n\r\nUseful interactive packages for shiny\r\nleaflet\r\nmapview package\r\nleaflet package\r\n\r\nplotly\r\nggiraph\r\n\r\nBeyond showing results\r\nI/O: Uploading files\r\nI/O: Saving user inputs\r\nI/O: Downloading\r\n\r\nAdditional resources\r\nLet’s get our hands dirty…\r\n\r\nDay’s learning objectives\r\nHave a good understanding of what Shiny apps can do and how it might be useful for you\r\nUnderstand the core structure of Shiny apps: UI, Server, Reactivity\r\nLearn how to create and run an App locally as well as deploy on ARI’s shiny account\r\nFeel confident enough to grab example code from Rshiny gallery ⛑\r\nKey packages\r\n\r\nProject for today\r\n\r\n\r\n Download Rstudio project\r\n\r\n\r\nFor background information on the dataset, see dataset summary\r\nPep talk\r\nOkay, before we get started, I think that it is useful to give a pep talk. For the more programming-phobic of you, the Shiny code will look foreign. You first reaction might be “for f*ksake, I am a researcher, not a programmer and I do not want to be programmer” and “are you serious after all this time I spent learning R coding and now I have to learn another type of programming??”\r\n\r\n\r\nShow code\r\n\r\nlibrary(shiny)\r\n\r\n# Define UI for application that draws a histogram\r\nui <- fluidPage(\r\n  fluidRow( \r\n    selectInput('x','X-Variable', choices = names(mtcars)),\r\n    selectInput('y','Y-Variable', choices = names(mtcars)),\r\n    plotOutput('plot') \r\n)\r\n)\r\n# Define server logic required to draw a histogram\r\nserver <- function(input, output, session) {\r\n  output$plot <- renderPlot({\r\n    plot( mtcars[,input$x], mtcars[,input$y] )\r\n    \r\n  })\r\n}# Run the application \r\n\r\nshinyApp(ui = ui, server = server)\r\n\r\n\r\nBut, we swear that it is not a bad at it looks. Once you get beyond the foreignness of the code, we guarantee that with a little guidance, you can easily get started making your own apps in minutes. It is just about getting the basic structure and then having the confidence to do “trial-and-error” with borrowed code. Just be forewarned, shiny Apps can become addicting!!!\r\nLet’s build one together\r\nGo through a simple example\r\nWe will work through an example of building a simple app that displays a graph depending on the conditions selected. The example will demonstrate AI here…\r\nWalk through the key bits\r\nSetting up the app\r\n\r\nFor you app setup, you can either select a single file called app.R [like we did in the example] or you can create two files: ui.R and server.R. What this is doing is just breaking up the one file into two, otherwise basically the same. The advantage of the latter is in larger apps and for reusing code. We will stick with one file method for rest of today.\r\nStructure of the file\r\n\r\n\r\nShow code\r\n\r\n\r\n# 1) Define extra packages and global objects (e.g. your dataset, model results, formats...)\r\nlibrary(shiny)\r\nlibrary(tidyverse)\r\n\r\n\r\n# 2) Define UI for application [how it looks to the user]\r\nui <- fluidPage(    \r\n  \r\n)\r\n\r\n# 3) Define server logic [steps taken when app starts and user clicks something]\r\nserver <- function(input, output) {\r\n}\r\n\r\n# 4) Run the application \r\nshinyApp(ui = ui, server = server)\r\n\r\n\r\n\r\nVisual model of the file…\r\n\r\nUI (= user interface)\r\nThis is what the user will be using to explore your data/results/visualizations.\r\nStep 1: pick a layout\r\nFirst step is determining what kind of layout you want. Single panel, main panel with sidepanel, tabs\r\nXXXXXX CREATE IMAGE OF DIFFERENT LAYOUTS XXXXXXX\r\nOf course the cheatsheet has some basic layout functions\r\n\r\nStep 2: create the inputs objects: buttons, inputs, drop-down menu\r\nOnce layout is figured out, now you add in the input objects. In our example that was a drop-down menu that allowed the user to pick cylinder size.\r\nAgain, cheatsheet has the basic ones listed for you\r\n\r\nFew key points\r\nbasically creating html using simple functions\r\nfunctions are separated by commas!!!!\r\nAnd so many nested brackets!!!!\r\ninput\r\nlike an R list\r\nsetup by the UI\r\ncan only be changed by the user (immutable from being changed in the server code)\r\nserver\r\nThe server is the heart of the app. Let revisit the visual model…\r\n\r\nThree main bits… 1) You have the inputs coming in that will be used 2) R code that will take the inputs and convert to new output(s) 3) the output list is created and exported back to UI\r\nNotes - Shiny uses reactive programming to make apps interactive. - not separated by commas…more like R programming but order does not matter!!! (except if within a reactive() or renderXXX() function - R code within reactive() and renderXXX() functions - double-breaks renderXXX({ }} when multiple lines\r\nLet’s look a little closer at the server code\r\n\r\n\r\nShow code\r\n\r\nserver <- function(input, output) {\r\n  output$scatterPlot <- renderPlot({\r\n    # Filter the data based on the selected number of cylinders\r\n    filteredData <- mtcars[mtcars$cyl == input$cyl, ]\r\n    \r\n    # Create the scatterplot with ggplot2\r\n    ggplot(filteredData, aes(x = hp, y = mpg)) +\r\n      geom_point() +\r\n      geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\r\n      labs(title = paste(\"Scatterplot of hp vs mpg for\", input$cyl, \"cylinders\"),\r\n           x = \"Horsepower (hp)\",\r\n           y = \"Miles per Gallon (mpg)\") +\r\n      theme_minimal()\r\n  })\r\n  \r\n}\r\n\r\n\r\n\r\nAlright, let’s look more at the options for output in the cheatsheet\r\n\r\nNote - this is not a comprehensive list and packages might have then own renderXxx() and xxxOutput()\r\n\r\n\r\nShow code\r\n\r\n  leaflet::renderLeaflet()   # server side for leaflets\r\n  leaflet::leafletOutput()   # UI side for leaflets\r\n\r\n\r\noutput\r\nbasically a list sending the outputs back to the UI to display\r\nkey bit here is that there are specific functions to output that pair up with renderXXX()\r\nFolder structure\r\nLittle more on the server side\r\nReactivity\r\nThe style of programming used in shiny apps is called “reactive programming”. The purpose of this programming style is to keep inputs and outputs in sync. To do this efficiency, you only want to update outputs that need to be changed. So the rule is “change if and only if inputs change”.\r\nThe two key components of this are called:\r\nlazy - only do work when called to [“procrastinate as long as possible”]\r\ncache - save the results produced when first called and use that until something changes\r\nYou will see a variety of functions that are doing “extra” bits in the programming:\r\n\r\n\r\nShow code\r\n\r\n  shiny::reactive()        # create function for repeated active (e.g. filtering dataset for multiple outputs )\r\n  shiny::reactiveValues()  # create a new reactive \"list\" like input and output\r\n  shiny::observe()         # performs a side effect, changes to input changes\r\n  shiny::observeEvent()    # performs when an event happens like submit button (e.g. input/output)\r\n  \r\n\r\n\r\nWe will not go into depth here but just want you to be aware and when you see them, know that they are doing extra stuff and a bit of efficiency stuff. For more complicated apps, they are essential to get a handle on…\r\nThink about how shiny Apps might be useful\r\nVisualising data for clients\r\nIbis Tracker - Nev’s masterpiece\r\nhttps://arisci.shinyapps.io/ibisTracker/\r\nData sharing - upload\r\nModel simulations\r\nCreating a shiny app using Rstudio\r\n\r\n\r\nShow code\r\n\r\n#install.packages(\"shiny\")\r\n\r\n\r\n\r\nYou can find a variety of cheatsheets at https://posit.co/resources/cheatsheets/\r\n\r\n\r\nShow code\r\n\r\n  knitr::include_graphics(\"shiny.pdf\")\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\n library(shiny) \r\n ui <- fluidPage(   \"Hello, world!\" ) \r\n server <- function(input, output, session) { } \r\n shinyApp(ui, server)\r\n\r\n\r\nShiny Templates\r\n\r\nhow might you look it up\r\nextras at < https://github.com/nanxstats/awesome-shiny-extensions>\r\nDashboards\r\nshinydashboards package\r\nThis package helps with setting up dashboard layouts (columns, rows, matrix) as well as a suite of html objects (e.g. messages, notifications), aesthetics (“skins”), and other more bespoke tools. Check out https://rstudio.github.io/shinydashboard/ for examples and overview.\r\nflexdashboard package\r\nFlexdashboard can be useful way to quickly create a layout using Rmarkdown-like file. At the simplest, you can create an interactive dashboard with no reactivity. If you want reactivity (e.g. inputs), then you can still use the template and integrate selectInput() functions and renderXXX() functions without explicitly defining ui/server. It is a bit of a hybrid approach between Rmarkdown/Quarto and shiny App. Not sure how much this package is still being developed??\r\nFor a range of examples: https://rstudio.github.io/flexdashboard/articles/examples.html\r\nAn example as a shiny App run in a Rmarkdown file, see https://jjallaire.shinyapps.io/shiny-ggplot2-diamonds/.\r\nDeploy your App\r\nARI shiny account\r\nThanks to Nev and Jim in particular 👏, we now have a ARI shiny Professional account (called arisci). This account is available to all ARI staff though we do have limits on the number of account users (max = 25 user accounts) but it can have an unlimited number of apps and has 10,000 usage hours (per month). The shiny apps are hosted on https://www.shinyapps.io/ and have https://arisci.shinyapps.io/XXAppNameXX address (e.g. https://arisci.shinyapps.io/ibisTracker/).\r\nSetting up a shiny account\r\nChat with others in your area and decide whether it may be useful to have a program-wide (similar) account for multiple users. If you are likely a higher user, it may be best to have your own account\r\nEmail Jim Thomson [“The Gatekeeper”] requesting\r\nYou will receive an invite to create an account. For your account, you will use your email (or designated person) as the username and then set a password\r\nlinking your Rstudio to shiny server\r\nAll account holders can access all the apps on the shared account. To ensure that you do not mess with other user’s apps accidentally please use the rsconnect package for all you uploading, modification, archiving and deletion of apps – you connection will have its own token. https://cran.r-project.org/web/packages/rsconnect/readme/README.html.\r\n\r\nIf you prefer, you can use rsconnect package via code. Get the name, token, and secret info from the token page when logged into https://www.shinyapps.io/.\r\n\r\n\r\nShow code\r\n\r\nrsconnect::setAccountInfo(name='arisci',\r\n                           token='XXXXX',\r\n                           secret='XXXXX' )  \r\n\r\n\r\nDeploying your app\r\nYou can use the publish approach via Rstudio (GUI approach):\r\n\r\nOr you can do the rsconnect way (just make sure the current directory is where the app is)\r\n\r\n\r\nShow code\r\n\r\nrsconnect::deployApp( ,)  \r\n\r\n# or if in a different directory, specify the directory\r\n\r\nrsconnect::deployApp('app/appAmazing' )  \r\n\r\n\r\nArchiving/deleting your app\r\nTo prevent deleting of others apps, you should archive the app using rsconnect code below. You can just type into Rconsole and run, assuming that you have setup your shiny connection (as shown above)\r\n\r\n\r\nShow code\r\n\r\nrsconnect::terminateApp(appName = 'appName')  # this will archive the app.\r\n\r\n\r\nPublishing Public apps\r\nAt the moment, a protocol is being developed to request that you can make your app “public” (sharing the link beyond biodiversity division) if it contains any data that is not otherwise public, or potentially have any sensitivities. For this to occur, a Manager/Director sign off will be required for the final published version. Until a formal process is solidified, an email with a brief description of the content of the app, its intended audience, and whether it will be password protected for end users or not along with the request should suffice. [from Nev]\r\nShiny Login Passwords/Security\r\nTwo possible approaches\r\n+ set app setting to private or public\r\n+ set up a login on your app\r\nPublic/private settings\r\nYou can do via deployApp\r\n\r\n\r\nShow code\r\n\r\nrsconnect::deployApp(appDir = \"your app\", appVisibility = \"private\")\r\n\r\n\r\nOr you can go onto shiny.io 1) go to your app info; 2) click on users, and 3) finally public.\r\nLogin\r\nCreating logins/passwords is another can of worms. There are multiple packages out there to help, e.g. shinyauthr, shinymanager. If you need at some point, probably a great question for QEARI and see what people are doing at the time.\r\nUseful interactive packages for shiny\r\ncan check https://r-graph-gallery.com/interactive-charts.html\r\nleaflet\r\nmapview package\r\nThe mapview package can be used to set up a simple, quick leaflet. This would be most useful when the leaflet is created on startup. For instance, you might want to show all the sites surveyed and attach metadata (e.g. dates surveyed, number of fish caught, number of plots) to that point.\r\n\r\n\r\nShow code\r\n\r\n  library(mapview)\r\n  mapview::mapview(breweries)\r\n\r\n\r\n\r\nUseful shiny functions for Server/UI…\r\n\r\n\r\nShow code\r\n\r\n  mapview::renderMapview()  # server side\r\n  mapview::mapviewOutput()  # UI side\r\n\r\n\r\nleaflet package\r\nNow, if you are going to build maps that will change with user input, it is best to build from “scratch” using leaflet package (+ other leaflet extra packages; see Justin’s intro on leaflet’s XXXXXXX)\r\nWhen you have user inputs affecting the map shown, you want to try to avoid rebuilding the map object and rather just modify the elements that the user wants changed (e.g. drop lines and add points instead). This requires using reactive programming and observe() functions. Ask Nev to share his app code or\r\nXXXXXX find apps to reference on gallery XXXXX\r\n\r\n\r\nShow code\r\n\r\n  library(leaflet)\r\n  sf_b <- mapview::breweries\r\n  leaflet(sf_b) %>% \r\n    addTiles() %>% \r\n    addMarkers()\r\n\r\n\r\n\r\nUseful shiny functions for Server/UI…\r\n\r\n\r\nShow code\r\n\r\n  leaflet::leafletOutput()  # UI side\r\n\r\n  leaflet::renderLeaflet()  # server side - creates the basemap\r\n  leaflet::leafletProxy()   # this is the server function that updates the map \r\n\r\n\r\nplotly\r\n\r\n\r\nShow code\r\n\r\n  library(ggplot2)\r\n  library(plotly)\r\n  f <- ggplot( cars, aes(speed, dist)  ) + geom_point() + geom_smooth()\r\n   plotly::ggplotly(f)\r\n\r\n\r\n\r\n\r\nUseful shiny functions for Server/UI…\r\n\r\n\r\nShow code\r\n\r\n  plotly::renderPlotly()\r\n  plotly::plotlyOutput()\r\n\r\n\r\nggiraph\r\nAgain, you cna build your plots using ggplot and convert\r\nI like this one for linking up plots…below, put your cursor over a dot on the left or a bar on the right\r\nIf you know CSS, it can be pretty powerful…\r\n\r\n\r\nShow code\r\n\r\nlibrary(ggiraph)\r\nlibrary(tidyverse)\r\nlibrary(patchwork)\r\n\r\nmtcars_db <- rownames_to_column(mtcars, var = \"carname\")\r\n\r\n# First plot: Scatter plot\r\nfig_pt <- ggplot(\r\n  data = mtcars_db,\r\n  mapping = aes(\r\n    x = disp, y = qsec,\r\n    tooltip = carname, data_id = carname\r\n  )\r\n) +\r\n  geom_point_interactive(\r\n    size = 3, hover_nearest = TRUE\r\n  ) +\r\n  labs(\r\n    title = \"Displacement vs Quarter Mile\",\r\n    x = \"Displacement\", y = \"Quarter Mile\"\r\n  ) +\r\n  theme_bw()\r\n\r\n# Second plot: Bar plot\r\nfig_bar <- ggplot(\r\n  data = mtcars_db,\r\n  mapping = aes(\r\n    x = reorder(carname, mpg), y = mpg,\r\n    tooltip = paste(\"Car:\", carname, \"<br>MPG:\", mpg),\r\n    data_id = carname\r\n  )\r\n) +\r\n  geom_col_interactive(fill = \"skyblue\") +\r\n  coord_flip() +\r\n  labs(\r\n    title = \"Miles per Gallon by Car\",\r\n    x = \"Car\", y = \"Miles per Gallon\"\r\n  ) +\r\n  theme_bw()\r\n\r\n# Combine the plots using patchwork\r\n combined_plot <- fig_pt + fig_bar + plot_layout(ncol = 2) \r\n\r\n# Combine the plots using cowplot\r\n# combined_plot <- cowplot::plot_grid(fig_pt, fig_bar, ncol=2) \r\n\r\n# Create a single interactive plot with both subplots\r\ninteractive_plot <- girafe(ggobj = combined_plot)\r\n\r\n# Set options for the interactive plot\r\ngirafe_options(\r\n  interactive_plot,\r\n  opts_hover(css = \"fill:cyan;stroke:black;cursor:pointer;\"),\r\n  opts_selection(type = \"single\", css = \"fill:red;stroke:black;\")\r\n)\r\n\r\n\r\n\r\n\r\nUseful shiny functions for Server/UI…\r\n\r\n\r\nShow code\r\n\r\n  ggiraph::renderGirafe()\r\n  ggiraph::ggiraphOutput()\r\n  \r\n\r\n\r\nBeyond showing results\r\nI/O: Uploading files\r\nI/O: Saving user inputs\r\nI/O: Downloading\r\nAdditional resources\r\nFor useful resources: https://shiny.posit.co/r/articles/ For useful examples: https://shiny.posit.co/r/articles/\r\nsee https://mastering-shiny.org/\r\n\r\nAsides can be useful for preso.\r\nLet’s get our hands dirty…\r\n\r\nYour Task\r\nBuild a shiny app to communicate Day 2 analysis results to your client\r\nStep1: setup your app page with the 4 parts: global, ui, server, run\r\nStep2: design a UI [ layout, user inputs to be passed to server]\r\nStep3: create server functions\r\nStep4: test your app by “Run App”\r\n\r\nYou can download our version:\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-09-11T13:04:36+10:00",
    "input_file": {}
  }
]
